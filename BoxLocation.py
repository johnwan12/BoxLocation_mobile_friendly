# BoxLocation.py ‚Äî Professional UI + Simple Workflow + Sticky Header + Tabs (NO DEBUG)
# ============================================================
# ‚úÖ Storage = LN Tank uses tab LN3 ONLY
# ‚úÖ Subset LN3 by TankID == LN1/LN2/LN3 and show LN Inventory Table
# ‚úÖ FIND tab:
#    - Storage=LN Tank: show LN Inventory Table (selected tank)
#    - Storage=Freezer: show Freezer Search by BoxLabel_group (selected freezer)
# ‚úÖ Box Location area:
#    - Storage=Freezer: ALWAYS visible (NOT an expander) with title "üì¶ {FREEZER}: Box Location"
#    - Storage=LN Tank: expander minimized/collapsed by default
# ‚úÖ Workflow tabs: Find / Add / Use / History / Session Report
# ‚úÖ Compact Context Bar always visible
# ‚úÖ Sticky header + sticky tabs (best-effort CSS)
# ‚úÖ QR is generated by QuickChart (no qrcode dependency)
# ‚úÖ fetch_bytes() disables proxies to reduce SSL WRONG_VERSION_NUMBER issues
# ‚úÖ After saving Freezer record:
#    - INSERT a NEW row into boxNumber tab:
#      * StudyID   = "Prefix + Tube suffix"
#      * BoxNumber = BoxID used in Freezer_Inventory ‚úÖ
# ‚úÖ When Freezer TubeAmount becomes 0:
#    - Delete the Freezer_Inventory row
#    - Delete matching boxNumber row(s) where StudyID == "Prefix + Tube suffix"
# ‚úÖ Download CSV file_name includes TubeNumber, Time_stamp, and ShippingTo
# ‚úÖ Mitigate Google Sheets 429 read quota using caching on reads (TTL)
#
# ‚úÖ Max BoxID rules (your request):
#    - Freezer add: max BoxID comes from boxNumber!BoxNumber
#    - LN add:      max BoxID comes from LN3!BoxID
# ============================================================

import re
import time
import random
import urllib.parse
import urllib.request
from datetime import datetime
from typing import Tuple, List

import pandas as pd
import pytz
import streamlit as st
from google.oauth2.service_account import Credentials
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError

# -------------------- Page --------------------
st.set_page_config(
    page_title="Sample Inventory",
    layout="centered",
    initial_sidebar_state="collapsed",
)

# -------------------- Sticky header + clean UI CSS --------------------
st.markdown(
    """
<style>
/* --- base spacing --- */
.block-container { padding-top: 0.75rem; }

/* --- sticky header (best-effort) --- */
[data-testid="stAppViewContainer"] > .main > div:first-child {
  position: sticky;
  top: 0;
  z-index: 999;
  background: rgba(255,255,255,0.92);
  backdrop-filter: blur(8px);
  border-bottom: 1px solid rgba(0,0,0,0.08);
}

/* --- sticky tabs (best-effort) --- */
.stTabs [data-baseweb="tab-list"] {
  position: sticky;
  top: 3.7rem; /* tweak if header height differs */
  z-index: 998;
  background: rgba(255,255,255,0.92);
  backdrop-filter: blur(8px);
  padding: 0.25rem 0;
  border-bottom: 1px solid rgba(0,0,0,0.06);
}

/* Compact header typography */
h1 { margin: 0.1rem 0 0.25rem 0; }
h2, h3 { margin-top: 0.6rem; }

/* Buttons full-width on mobile */
@media (max-width: 640px) {
  .block-container { padding-left: 0.8rem; padding-right: 0.8rem; padding-top: 0.6rem; }
  h1 { font-size: 1.35rem; }
  h2 { font-size: 1.1rem; }
  h3 { font-size: 1.02rem; }
  .stButton>button, .stDownloadButton>button { width: 100%; }
  .stTextInput>div>div>input,
  .stNumberInput>div>div>input,
  .stSelectbox>div>div,
  .stTextArea textarea { font-size: 1rem; }
}

/* Dataframe padding */
div[data-testid="stDataFrame"] { padding: 0.25rem 0; }

/* Tabs look a little more ‚Äúapp-like‚Äù */
.stTabs [data-baseweb="tab-list"] { gap: 0.25rem; }
.stTabs [data-baseweb="tab"] {
  padding: 8px 12px;
  border-radius: 10px;
}
.stTabs [aria-selected="true"] {
  border-bottom: none !important;
  background: rgba(0,0,0,0.05);
}

/* Optional: subtle card for always-visible freezer box location */
.boxloc-card {
  border: 1px solid rgba(0,0,0,0.08);
  background: rgba(0,0,0,0.02);
  border-radius: 12px;
  padding: 12px 12px 6px 12px;
  margin: 6px 0 10px 0;
}
</style>
""",
    unsafe_allow_html=True,
)

# -------------------- Session State --------------------
if "last_qr_link" not in st.session_state:
    st.session_state.last_qr_link = ""
if "last_qr_uid" not in st.session_state:
    st.session_state.last_qr_uid = ""
if "usage_final_rows" not in st.session_state:
    st.session_state.usage_final_rows = []
if "mobile_mode" not in st.session_state:
    st.session_state.mobile_mode = True

# -------------------- Constants --------------------
DISPLAY_TABS = ["Cocaine", "Cannabis", "HIV-neg-nondrug", "HIV+nondrug"]
TAB_MAP = {
    "Cocaine": "cocaine",
    "Cannabis": "cannabis",
    "HIV-neg-nondrug": "HIV-neg-nondrug",
    "HIV+nondrug": "HIV+nondrug",
}

BOX_TAB = "boxNumber"
LN_TAB = "LN3"  # Always LN in LN3 tab
FREEZER_TAB = "Freezer_Inventory"
USE_LOG_TAB = "Use_log"

# Shared columns
BOX_LABEL_COL = "BoxLabel_group"
BOXID_COL = "BoxID"
AMT_COL = "TubeAmount"
MEMO_COL = "Memo"

# LN columns
TANK_COL = "TankID"
RACK_COL = "RackNumber"
TUBE_COL = "TubeNumber"
BOXUID_COL = "BoxUID"
QR_COL = "QRCodeLink"

# Freezer columns
FREEZER_COL = "FreezerID"
PREFIX_COL = "Prefix"
SUFFIX_COL = "Tube suffix"
DATE_COLLECTED_COL = "Date Collected"
SAMPLES_RECEIVED_COL = "Samples Received"
MISSING_COL = "Missing"
URINE_RESULTS_COL = "Urine Results"
COLLECTED_BY_COL = "Collected By"

HIV_CODE = {"HIV+": "HP", "HIV-": "HN"}
DRUG_CODE = {"Cocaine": "COC", "Cannabis": "CAN", "Poly": "POL", "NON-DRUG": "NON-DRUG"}

QR_PX = 118
SPREADSHEET_ID = st.secrets["connections"]["gsheets"]["spreadsheet"]
NY_TZ = pytz.timezone("America/New_York")

# -------------------- Google Sheets service --------------------
@st.cache_resource(show_spinner=False)
def sheets_service():
    scopes = ["https://www.googleapis.com/auth/spreadsheets"]
    creds = Credentials.from_service_account_info(dict(st.secrets["google_service_account"]), scopes=scopes)
    return build("sheets", "v4", credentials=creds, cache_discovery=False)

# -------------------- Helpers --------------------
def safe_strip(x) -> str:
    return "" if x is None else str(x).strip()

def normalize_spaces(s: str) -> str:
    return re.sub(r"\s+", " ", safe_strip(s))

def to_int_amount(x, default=0) -> int:
    try:
        s = safe_strip(x)
        if s == "":
            return default
        return int(float(s))
    except Exception:
        return default

def col_to_a1(col_idx_0based: int) -> str:
    n = col_idx_0based + 1
    s = ""
    while n:
        n, r = divmod(n - 1, 26)
        s = chr(65 + r) + s
    return s

def now_timestamp_str() -> str:
    now = datetime.now(NY_TZ)
    time_str = now.strftime("%I:%M:%S").lstrip("0") or now.strftime("%I:%M:%S")
    date_str = now.strftime("%m/%d/%Y")
    return f"{time_str} {date_str}"

def today_str_ny() -> str:
    d = datetime.now(NY_TZ).date()
    return d.strftime("%m/%d/%Y")

def split_tube_number(t: str) -> Tuple[str, str]:
    t = normalize_spaces(t)
    if not t:
        return "", ""
    parts = t.split(" ", 1)
    if len(parts) == 1:
        return parts[0], ""
    return parts[0], parts[1]

def qr_link_for_boxuid(box_uid: str, px: int = QR_PX) -> str:
    text = urllib.parse.quote(box_uid, safe="")
    return f"https://quickchart.io/qr?text={text}&size={px}&ecLevel=Q&margin=1"

def fetch_bytes(url: str, timeout: int = 12) -> bytes:
    req = urllib.request.Request(url, headers={"User-Agent": "Mozilla/5.0"})
    opener = urllib.request.build_opener(urllib.request.ProxyHandler({}))
    with opener.open(req, timeout=timeout) as resp:
        return resp.read()

def read_tab(tab_name: str) -> pd.DataFrame:
    svc = sheets_service()
    resp = svc.spreadsheets().values().get(
        spreadsheetId=SPREADSHEET_ID,
        range=f"{tab_name}!A1:ZZ",
        valueRenderOption="UNFORMATTED_VALUE",
    ).execute()

    values = resp.get("values", [])
    if not values:
        return pd.DataFrame()

    header_raw = [safe_strip(h) for h in values[0]]
    last = max([i for i, h in enumerate(header_raw) if h != ""], default=-1)
    header = header_raw[: last + 1] if last >= 0 else []
    rows = values[1:]
    n = len(header)

    if n == 0:
        return pd.DataFrame()

    fixed = []
    for r in rows:
        r = list(r)
        if len(r) < n:
            r += [""] * (n - len(r))
        elif len(r) > n:
            r = r[:n]
        fixed.append(r)

    return pd.DataFrame(fixed, columns=header)

def read_tab_with_backoff(tab_name: str, tries: int = 5) -> pd.DataFrame:
    for i in range(tries):
        try:
            return read_tab(tab_name)
        except HttpError as e:
            msg = str(e)
            if "429" in msg or "RESOURCE_EXHAUSTED" in msg or "RATE_LIMIT_EXCEEDED" in msg:
                time.sleep((2 ** i) + random.random())
                continue
            raise
    raise RuntimeError(f"Read quota exceeded too long when reading {tab_name}. Try again in ~1 minute.")

@st.cache_data(ttl=30, show_spinner=False)
def read_tab_cached(tab_name: str) -> pd.DataFrame:
    return read_tab_with_backoff(tab_name)

@st.cache_data(ttl=300, show_spinner=False)
def get_sheet_titles(spreadsheet_id: str) -> list:
    svc = sheets_service()
    meta = svc.spreadsheets().get(spreadsheetId=spreadsheet_id).execute()
    return [s["properties"]["title"] for s in meta.get("sheets", [])]

@st.cache_data(show_spinner=False)
def get_sheet_id_map(spreadsheet_id: str) -> dict:
    svc = sheets_service()
    meta = svc.spreadsheets().get(spreadsheetId=spreadsheet_id).execute()
    return {s["properties"]["title"]: int(s["properties"]["sheetId"]) for s in meta.get("sheets", [])}

def get_sheet_id(service, sheet_title: str) -> int:
    m = get_sheet_id_map(SPREADSHEET_ID)
    if sheet_title in m:
        return m[sheet_title]
    raise ValueError(f"Could not find sheetId for tab: {sheet_title}")

def get_header(service, tab: str) -> list:
    resp = service.spreadsheets().values().get(
        spreadsheetId=SPREADSHEET_ID,
        range=f"{tab}!A1:ZZ1",
        valueRenderOption="UNFORMATTED_VALUE",
    ).execute()
    row1 = (resp.get("values", [[]]) or [[]])[0]
    row1 = [safe_strip(x) for x in row1]
    last = max([i for i, h in enumerate(row1) if h != ""], default=-1)
    return row1[: last + 1] if last >= 0 else []

def set_header_if_blank(service, tab: str, header: list):
    resp = service.spreadsheets().values().get(
        spreadsheetId=SPREADSHEET_ID,
        range=f"{tab}!A1:ZZ1",
        valueRenderOption="UNFORMATTED_VALUE",
    ).execute()
    row1 = (resp.get("values", [[]]) or [[]])[0]
    row1 = [safe_strip(x) for x in row1]
    if (not row1) or all(x == "" for x in row1):
        service.spreadsheets().values().update(
            spreadsheetId=SPREADSHEET_ID,
            range=f"{tab}!A1",
            valueInputOption="RAW",
            body={"values": [header]},
        ).execute()

def append_row_by_header(service, tab: str, data: dict):
    header = get_header(service, tab)
    if not header:
        raise ValueError(f"{tab} header row is empty.")
    aligned = [data.get(col, "") for col in header]
    service.spreadsheets().values().append(
        spreadsheetId=SPREADSHEET_ID,
        range=f"{tab}!A:ZZ",
        valueInputOption="RAW",
        insertDataOption="INSERT_ROWS",
        body={"values": [aligned]},
    ).execute()

def cleanup_zero_amount_rows(service, tab_name: str, df: pd.DataFrame, amount_col: str = AMT_COL) -> List[int]:
    if df is None or df.empty or amount_col not in df.columns:
        return []
    amounts = pd.to_numeric(df[amount_col], errors="coerce").fillna(0).astype(int)
    zero_idxs = [int(i) for i in df.index[amounts == 0].tolist()]
    if not zero_idxs:
        return []

    sheet_id = get_sheet_id(service, tab_name)
    zero_idxs.sort(reverse=True)
    requests = [{
        "deleteDimension": {
            "range": {
                "sheetId": sheet_id,
                "dimension": "ROWS",
                "startIndex": idx0 + 1,
                "endIndex": idx0 + 2,
            }
        }
    } for idx0 in zero_idxs]

    for i in range(0, len(requests), 400):
        service.spreadsheets().batchUpdate(
            spreadsheetId=SPREADSHEET_ID,
            body={"requests": requests[i:i + 400]},
        ).execute()
    return zero_idxs

def update_amount_by_index(service, tab_name: str, idx0: int, amount_col: str, new_amount: int):
    header = get_header(service, tab_name)
    if amount_col not in header:
        raise ValueError(f"{tab_name} missing '{amount_col}' column in header.")
    col_idx = header.index(amount_col)
    a1_col = col_to_a1(col_idx)
    sheet_row = idx0 + 2
    service.spreadsheets().values().update(
        spreadsheetId=SPREADSHEET_ID,
        range=f"{tab_name}!{a1_col}{sheet_row}",
        valueInputOption="RAW",
        body={"values": [[int(new_amount)]]},
    ).execute()

def delete_row_by_index(service, tab_name: str, idx0: int):
    sheet_id = get_sheet_id(service, tab_name)
    start = idx0 + 1
    service.spreadsheets().batchUpdate(
        spreadsheetId=SPREADSHEET_ID,
        body={"requests": [{
            "deleteDimension": {
                "range": {
                    "sheetId": sheet_id,
                    "dimension": "ROWS",
                    "startIndex": start,
                    "endIndex": start + 1,
                }
            }
        }]},
    ).execute()

def compute_next_boxuid(ln_view_df: pd.DataFrame, tank_id: str, rack: int, hp_hn: str, drug_code: str) -> str:
    tank_id = safe_strip(tank_id).upper()
    prefix = f"{tank_id}-R{int(rack):02d}-{hp_hn}-{drug_code}-"
    max_n = 0
    if ln_view_df is not None and (not ln_view_df.empty) and (BOXUID_COL in ln_view_df.columns):
        for v in ln_view_df[BOXUID_COL].dropna().astype(str):
            s = v.strip()
            if s.startswith(prefix) and re.search(r"-(\d{2})$", s):
                try:
                    n = int(s.split("-")[-1])
                    max_n = max(max_n, n)
                except ValueError:
                    pass
    nxt = max_n + 1
    if nxt > 99:
        raise ValueError(f"BoxUID sequence exceeded 99 for {prefix}**")
    return f"{prefix}{nxt:02d}"

def ensure_ln_header(service):
    set_header_if_blank(service, LN_TAB, [
        "TankID", "RackNumber", "BoxLabel_group", "BoxUID",
        "TubeNumber", "TubeAmount", "Memo", "BoxID", "QRCodeLink",
    ])

def ensure_freezer_header(service):
    set_header_if_blank(service, FREEZER_TAB, [
        "FreezerID", "BoxID", "Prefix", "Tube suffix", "TubeAmount",
        "Date Collected", "BoxLabel_group", "Samples Received",
        "Missing", "Urine Results", "Collected By", "Memo",
    ])

def ensure_use_log_header(service):
    set_header_if_blank(service, USE_LOG_TAB, [
        "StorageType", "TankID", "RackNumber", "FreezerID",
        "BoxLabel_group", "BoxID", "TubeNumber", "Prefix", "Tube suffix",
        "Use", "User", "Time_stamp", "ShippingTo", "Memo",
    ])

def ensure_boxnumber_header(service):
    set_header_if_blank(service, BOX_TAB, ["StudyID", "BoxNumber"])

def insert_boxnumber_row(service, study_id_value: str, box_number_value: str):
    ensure_boxnumber_header(service)
    append_row_by_header(
        service,
        BOX_TAB,
        {"StudyID": safe_strip(study_id_value), "BoxNumber": safe_strip(box_number_value)},
    )

def delete_boxnumber_rows_by_studyid(service, study_id_value: str) -> int:
    ensure_boxnumber_header(service)
    df = read_tab_cached(BOX_TAB)
    if df is None or df.empty or "StudyID" not in df.columns:
        return 0

    target = normalize_spaces(study_id_value)
    df2 = df.copy()
    df2["StudyID"] = df2["StudyID"].astype(str).map(normalize_spaces)

    hit_idxs = [int(i) for i in df2.index[df2["StudyID"] == target].tolist()]
    if not hit_idxs:
        return 0

    sheet_id = get_sheet_id(service, BOX_TAB)
    hit_idxs.sort(reverse=True)

    requests = []
    for idx0 in hit_idxs:
        requests.append({
            "deleteDimension": {
                "range": {
                    "sheetId": sheet_id,
                    "dimension": "ROWS",
                    "startIndex": idx0 + 1,
                    "endIndex": idx0 + 2,
                }
            }
        })

    for i in range(0, len(requests), 400):
        service.spreadsheets().batchUpdate(
            spreadsheetId=SPREADSHEET_ID,
            body={"requests": requests[i:i + 400]},
        ).execute()

    return len(hit_idxs)

def freezer_studyid_from_row(df: pd.DataFrame, idx0: int) -> str:
    try:
        p = safe_strip(df.loc[idx0, PREFIX_COL]).upper()
        s = safe_strip(df.loc[idx0, SUFFIX_COL])
        return normalize_spaces(f"{p} {s}".strip())
    except Exception:
        return ""

# -------------------- Max BoxID rules --------------------
def get_current_max_boxid_from_boxnumber() -> int:
    try:
        df = read_tab_cached(BOX_TAB)
        if df is None or df.empty:
            return 0
        if "BoxNumber" not in df.columns:
            return 0
        s = pd.to_numeric(df["BoxNumber"], errors="coerce").dropna()
        return int(s.max()) if not s.empty else 0
    except Exception:
        return 0

def get_current_max_boxid_from_ln3() -> int:
    try:
        df = read_tab_cached(LN_TAB)
        if df is None or df.empty:
            return 0
        if BOXID_COL not in df.columns:
            return 0
        s = pd.to_numeric(df[BOXID_COL], errors="coerce").dropna()
        return int(s.max()) if not s.empty else 0
    except Exception:
        return 0

def build_use_log_row(storage_type, tank_id, rack_number, freezer_id, box_label_group, boxid,
                      prefix, suffix, use_amt, user_initials, shipping_to, memo_in, time_stamp: str) -> dict:
    tube_number_combined = normalize_spaces(f"{safe_strip(prefix).upper()} {safe_strip(suffix)}".strip())
    return {
        "StorageType": safe_strip(storage_type),
        "TankID": safe_strip(tank_id).upper(),
        "RackNumber": safe_strip(rack_number),
        "FreezerID": safe_strip(freezer_id).upper(),
        "BoxLabel_group": safe_strip(box_label_group),
        "BoxID": safe_strip(boxid),
        "TubeNumber": tube_number_combined,
        "Prefix": safe_strip(prefix).upper(),
        "Tube suffix": safe_strip(suffix),
        "Use": int(use_amt),
        "User": safe_strip(user_initials).upper(),
        "Time_stamp": safe_strip(time_stamp),
        "ShippingTo": safe_strip(shipping_to),
        "Memo": safe_strip(memo_in),
    }

def build_final_report_row(storage_type, storage_id, box_label_group, boxid, prefix, suffix,
                           use_amt, user_initials, time_stamp, shipping_to, memo) -> dict:
    return {
        "StorageType": safe_strip(storage_type),
        "StorageID": safe_strip(storage_id).upper(),
        "BoxLabel_group": safe_strip(box_label_group),
        "BoxID": safe_strip(boxid),
        "Prefix": safe_strip(prefix).upper(),
        "Tube suffix": safe_strip(suffix),
        "Use": int(use_amt),
        "User": safe_strip(user_initials).upper(),
        "Time_stamp": safe_strip(time_stamp),
        "ShippingTo": safe_strip(shipping_to),
        "Memo": safe_strip(memo),
    }

def find_ln_row_index(ln_all_df: pd.DataFrame, tank_id: str, box_label_group: str, boxid: str, tube_number: str):
    if ln_all_df is None or ln_all_df.empty:
        return None, None
    needed = {TANK_COL, BOX_LABEL_COL, BOXID_COL, TUBE_COL, AMT_COL}
    if not needed.issubset(set(ln_all_df.columns)):
        return None, None

    df = ln_all_df.copy()
    df[TANK_COL] = df[TANK_COL].astype(str).map(lambda x: safe_strip(x).upper())
    df[BOX_LABEL_COL] = df[BOX_LABEL_COL].astype(str).map(safe_strip)
    df[BOXID_COL] = df[BOXID_COL].astype(str).map(safe_strip)
    df[TUBE_COL] = df[TUBE_COL].astype(str).map(normalize_spaces)

    tube_number_norm = normalize_spaces(tube_number)
    mask = (
        (df[TANK_COL] == safe_strip(tank_id).upper()) &
        (df[BOX_LABEL_COL] == safe_strip(box_label_group)) &
        (df[BOXID_COL] == safe_strip(boxid)) &
        (df[TUBE_COL] == tube_number_norm)
    )
    hits = df[mask]
    if hits.empty:
        return None, None
    idx0 = int(hits.index[0])
    cur_amount = to_int_amount(hits.iloc[0].get(AMT_COL, 0), default=0)
    return idx0, cur_amount

def get_ln_racknumber_by_index(ln_all_df: pd.DataFrame, idx0: int) -> str:
    try:
        if ln_all_df is None or ln_all_df.empty:
            return ""
        if RACK_COL not in ln_all_df.columns:
            return ""
        return safe_strip(ln_all_df.loc[idx0, RACK_COL])
    except Exception:
        return ""

def find_freezer_row_index(fr_all_df: pd.DataFrame, freezer_id: str, box_label_group: str, boxid: str, prefix: str, suffix: str):
    if fr_all_df is None or fr_all_df.empty:
        return None, None
    needed = {FREEZER_COL, BOX_LABEL_COL, BOXID_COL, PREFIX_COL, SUFFIX_COL, AMT_COL}
    if not needed.issubset(set(fr_all_df.columns)):
        return None, None

    df = fr_all_df.copy()
    df[FREEZER_COL] = df[FREEZER_COL].astype(str).map(lambda x: safe_strip(x).upper())
    df[BOX_LABEL_COL] = df[BOX_LABEL_COL].astype(str).map(safe_strip)
    df[BOXID_COL] = df[BOXID_COL].astype(str).map(safe_strip)
    df[PREFIX_COL] = df[PREFIX_COL].astype(str).map(lambda x: safe_strip(x).upper())
    df[SUFFIX_COL] = df[SUFFIX_COL].astype(str).map(normalize_spaces)

    suffix_norm = normalize_spaces(suffix)
    mask = (
        (df[FREEZER_COL] == safe_strip(freezer_id).upper()) &
        (df[BOX_LABEL_COL] == safe_strip(box_label_group)) &
        (df[BOXID_COL] == safe_strip(boxid)) &
        (df[PREFIX_COL] == safe_strip(prefix).upper()) &
        (df[SUFFIX_COL] == suffix_norm)
    )
    hits = df[mask]
    if hits.empty:
        return None, None
    idx0 = int(hits.index[0])
    cur_amount = to_int_amount(hits.iloc[0].get(AMT_COL, 0), default=0)
    return idx0, cur_amount

def show_df_view(df: pd.DataFrame, key_cols: list, height_mobile: int = 360, height_desktop: int = 520, key_prefix: str = "df"):
    if df is None or df.empty:
        st.info("No records.")
        return

    show_all = st.checkbox(
        "Show all columns",
        value=not st.session_state.mobile_mode,
        key=f"{key_prefix}_show_all",
    )

    if st.session_state.mobile_mode and not show_all:
        cols = [c for c in key_cols if c in df.columns]
        st.dataframe(df[cols] if cols else df, use_container_width=True, hide_index=True, height=height_mobile)
    else:
        st.dataframe(df, use_container_width=True, hide_index=True, height=height_desktop)

def build_box_map() -> dict:
    df = read_tab_cached(BOX_TAB)
    if df.empty:
        return {}
    study_candidates = ["StudyID", "Study ID", "Study Id", "ID"]
    box_candidates = ["BoxNumber", "Box Number", "Box", "Box#", "Box #"]
    study_col = next((c for c in study_candidates if c in df.columns), None)
    box_col = next((c for c in box_candidates if c in df.columns), None)
    if study_col is None or box_col is None:
        return {}
    m = {}
    for _, r in df.iterrows():
        sid = safe_strip(r.get(study_col, "")).upper()
        bx = safe_strip(r.get(box_col, ""))
        if sid:
            m[sid] = bx
    return m

# -------------------- Download filename helpers --------------------
def sanitize_filename_part(s: str, max_len: int = 40) -> str:
    s = safe_strip(s)
    if not s:
        return "NA"
    s = re.sub(r"\s+", "_", s.strip())
    s = re.sub(r"[^A-Za-z0-9_.-]+", "-", s)
    s = s.strip("._-")
    return s[:max_len] if len(s) > max_len else s

def timestamp_for_filename(ts: str) -> str:
    ts = safe_strip(ts)
    try:
        dt = datetime.strptime(ts, "%I:%M:%S %m/%d/%Y")
        return dt.strftime("%Y-%m-%d_%H-%M-%S")
    except Exception:
        return sanitize_filename_part(ts, max_len=30)

def build_report_filename(df: pd.DataFrame, prefix: str = "report", ext: str = "csv") -> str:
    if df is None or df.empty:
        return f"{prefix}_EMPTY.{ext}"

    tube_col = "TubeNumber" if "TubeNumber" in df.columns else None
    ship_col = "ShippingTo" if "ShippingTo" in df.columns else None
    ts_col = "Time_stamp" if "Time_stamp" in df.columns else None

    row = df.iloc[-1]
    tube = sanitize_filename_part(row.get(tube_col, "NA")) if tube_col else "NA"
    ship = sanitize_filename_part(row.get(ship_col, "NA")) if ship_col else "NA"
    ts = timestamp_for_filename(row.get(ts_col, "")) if ts_col else sanitize_filename_part(today_str_ny())
    return f"{prefix}_Tube-{tube}_Ship-{ship}_TS-{ts}.{ext}"

# ============================================================
# Preflight (NO DEBUG)
# ============================================================
service = sheets_service()

try:
    titles = get_sheet_titles(SPREADSHEET_ID)
except Exception:
    st.error("‚ùå Unable to connect to Google Sheets.")
    st.stop()

required_tabs = [USE_LOG_TAB, LN_TAB, FREEZER_TAB, BOX_TAB]
study_required = list(TAB_MAP.values())
missing_tabs = [t for t in required_tabs if t not in titles]
missing_study = [t for t in study_required if t not in titles]

if missing_tabs or missing_study:
    st.error("‚ùå Google Sheet is missing required tabs.")
    if missing_tabs:
        st.caption(f"Missing required tabs: {missing_tabs}")
    if missing_study:
        st.caption(f"Missing study tabs: {missing_study}")
    st.stop()

try:
    _ = get_sheet_id_map(SPREADSHEET_ID)
    ensure_use_log_header(service)
    ensure_ln_header(service)
    ensure_freezer_header(service)
    ensure_boxnumber_header(service)
except Exception:
    st.error("‚ùå Sheet preflight failed (headers/tabs).")
    st.stop()

# ============================================================
# Header: title + status + context
# ============================================================
st.title("üì¶ Sample Inventory")

c_status, c_toggle = st.columns([1, 1])
with c_status:
    st.success("Connected", icon="‚úÖ")
with c_toggle:
    st.session_state.mobile_mode = st.toggle("üì± Mobile", value=st.session_state.mobile_mode)

# -------------------- Context Bar --------------------
ctx1, ctx2, ctx3 = st.columns([1.25, 1, 1])
with ctx1:
    selected_display_tab = st.selectbox("Study", DISPLAY_TABS, index=0, key="ctx_study")
with ctx2:
    STORAGE_TYPE = st.selectbox("Storage", ["LN Tank", "Freezer"], index=0, key="ctx_storage")
with ctx3:
    if STORAGE_TYPE == "LN Tank":
        selected_tank = st.selectbox("Tank", ["LN1", "LN2", "LN3"], index=2, key="ctx_tank")
        selected_freezer = None
    else:
        selected_freezer = st.selectbox("Freezer", ["Sammy", "Tom", "Jerry"], index=0, key="ctx_freezer")
        selected_tank = None

# ============================================================
# Top-level mode tabs
# ============================================================
tab_find, tab_add, tab_use, tab_history, tab_session = st.tabs(
    ["üîé Find", "‚ûï Add", "üìâ Use", "üßæ History", "‚úÖ Session Report"]
)

# ============================================================
# FIND
# ============================================================
with tab_find:
    st.subheader("Find / Locate")

    boxloc_title = f"üì¶ {safe_strip(selected_freezer).upper()}: Box Location" if STORAGE_TYPE == "Freezer" else "üì¶ Box Location"

    if STORAGE_TYPE == "Freezer":
        # ‚úÖ ALWAYS visible (NOT an expander), so it cannot be minimized
        st.markdown(f"<div class='boxloc-card'><h3>{boxloc_title}</h3></div>", unsafe_allow_html=True)

        tab_name = TAB_MAP[selected_display_tab]
        try:
            df = read_tab_cached(tab_name)
            if df.empty:
                st.info(f"No data found in tab: {tab_name}")
            else:
                show_df_view(
                    df,
                    key_cols=["StudyID", "Visit", "SampleID", "Memo"],
                    height_mobile=360,
                    height_desktop=520,
                    key_prefix="find_boxloc",
                )

                st.markdown("**StudyID ‚Üí BoxNumber**")
                if "StudyID" not in df.columns:
                    st.info("This tab does not have a 'StudyID' column.")
                else:
                    studyids = df["StudyID"].dropna().astype(str).map(safe_strip)
                    options = sorted([s for s in studyids.unique().tolist() if s])
                    selected_studyid = st.selectbox("StudyID", ["(select)"] + options, key="find_studyid")
                    if selected_studyid != "(select)":
                        box_map = build_box_map()
                        box = box_map.get(safe_strip(selected_studyid).upper(), "")
                        if safe_strip(box) == "":
                            st.error("BoxNumber: Not Found")
                        else:
                            st.success(f"BoxNumber: {box}")
        except Exception:
            st.error("Box Location failed.")

    else:
        # ‚úÖ LN Tank: minimized/collapsed by default
        with st.expander(boxloc_title, expanded=False):
            tab_name = TAB_MAP[selected_display_tab]
            try:
                df = read_tab_cached(tab_name)
                if df.empty:
                    st.info(f"No data found in tab: {tab_name}")
                else:
                    show_df_view(
                        df,
                        key_cols=["StudyID", "Visit", "SampleID", "Memo"],
                        height_mobile=360,
                        height_desktop=520,
                        key_prefix="find_boxloc",
                    )

                    st.markdown("**StudyID ‚Üí BoxNumber**")
                    if "StudyID" not in df.columns:
                        st.info("This tab does not have a 'StudyID' column.")
                    else:
                        studyids = df["StudyID"].dropna().astype(str).map(safe_strip)
                        options = sorted([s for s in studyids.unique().tolist() if s])
                        selected_studyid = st.selectbox("StudyID", ["(select)"] + options, key="find_studyid")
                        if selected_studyid != "(select)":
                            box_map = build_box_map()
                            box = box_map.get(safe_strip(selected_studyid).upper(), "")
                            if safe_strip(box) == "":
                                st.error("BoxNumber: Not Found")
                            else:
                                st.success(f"BoxNumber: {box}")
            except Exception:
                st.error("Box Location failed.")

    if STORAGE_TYPE == "LN Tank":
        with st.expander(f"üßä LN Inventory Table ({selected_tank})", expanded=True):
            try:
                ln_all_df = read_tab_cached(LN_TAB)
                if ln_all_df.empty:
                    st.info("LN3 is empty.")
                else:
                    try:
                        deleted_idxs = cleanup_zero_amount_rows(service, LN_TAB, ln_all_df, AMT_COL)
                        if deleted_idxs:
                            read_tab_cached.clear()
                            ln_all_df = read_tab_cached(LN_TAB)
                    except Exception:
                        pass

                    if TANK_COL not in ln_all_df.columns:
                        st.error(f"LN3 missing required column: '{TANK_COL}'")
                    else:
                        ln_view_df = ln_all_df.copy()
                        ln_view_df[TANK_COL] = ln_view_df[TANK_COL].astype(str).map(lambda x: safe_strip(x).upper())
                        ln_view_df = ln_view_df[ln_view_df[TANK_COL] == safe_strip(selected_tank).upper()].copy()

                        if ln_view_df.empty:
                            st.info(f"No records for {selected_tank}.")
                        else:
                            show_df_view(
                                ln_view_df,
                                key_cols=[TANK_COL, RACK_COL, BOX_LABEL_COL, BOXID_COL, TUBE_COL, AMT_COL, MEMO_COL],
                                height_mobile=360,
                                height_desktop=520,
                                key_prefix="find_ln_table",
                            )
            except Exception:
                st.error("Failed to load LN inventory.")
    else:
        with st.expander("üßä Freezer Search by BoxLabel_group", expanded=True):
            try:
                fr_all_df = read_tab_cached(FREEZER_TAB)
                if fr_all_df.empty:
                    st.info("Freezer_Inventory is empty.")
                elif BOX_LABEL_COL not in fr_all_df.columns:
                    st.error(f"Missing column '{BOX_LABEL_COL}' in {FREEZER_TAB}.")
                else:
                    df_search = fr_all_df.copy()
                    if FREEZER_COL in df_search.columns:
                        df_search[FREEZER_COL] = df_search[FREEZER_COL].astype(str).map(lambda x: safe_strip(x).upper())

                    df_search = df_search[df_search[FREEZER_COL] == safe_strip(selected_freezer).upper()].copy()
                    df_search[BOX_LABEL_COL] = df_search[BOX_LABEL_COL].astype(str).map(safe_strip)
                    groups = sorted([g for g in df_search[BOX_LABEL_COL].dropna().unique().tolist() if safe_strip(g)])

                    mode = st.radio("Mode", ["Exact", "Contains"], horizontal=not st.session_state.mobile_mode, key="find_fr_mode")
                    if mode == "Exact":
                        chosen_group = st.selectbox("BoxLabel_group", ["(select)"] + groups, key="find_fr_group_exact")
                        if chosen_group != "(select)":
                            out = df_search[df_search[BOX_LABEL_COL] == safe_strip(chosen_group)].copy()
                            st.caption(f"Matches: {len(out)}")
                            show_df_view(
                                out,
                                key_cols=[FREEZER_COL, BOX_LABEL_COL, BOXID_COL, PREFIX_COL, SUFFIX_COL, AMT_COL, DATE_COLLECTED_COL, MEMO_COL],
                                height_mobile=320,
                                height_desktop=420,
                                key_prefix="find_fr_exact",
                            )
                    else:
                        q = st.text_input("BoxLabel_group contains‚Ä¶", placeholder="e.g., HP-COC", key="find_fr_contains").strip()
                        if q:
                            out = df_search[df_search[BOX_LABEL_COL].astype(str).str.lower().str.contains(q.lower(), na=False)].copy()
                            st.caption(f"Matches: {len(out)}")
                            show_df_view(
                                out,
                                key_cols=[FREEZER_COL, BOX_LABEL_COL, BOXID_COL, PREFIX_COL, SUFFIX_COL, AMT_COL, DATE_COLLECTED_COL, MEMO_COL],
                                height_mobile=320,
                                height_desktop=420,
                                key_prefix="find_fr_contains_view",
                            )
                        else:
                            st.info("Type a search term to filter.")
            except Exception:
                st.error("Freezer search failed.")

# ============================================================
# ADD / USE / HISTORY / SESSION REPORT
# ============================================================
# NOTE: Your original code for these sections continues unchanged.
# Paste the remainder of your previous script (from "# ADD" onward) below this line.
# ============================================================

st.info("‚ö†Ô∏è Paste the remainder of your original code below (ADD/USE/HISTORY/SESSION REPORT) to complete the file.")
